{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import util\n",
    "# pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from collections import OrderedDict\n",
    "from time import time\n",
    "import os\n",
    "\n",
    "from scipy.optimize import fmin_powell\n",
    "from scipy import integrate\n",
    "\n",
    "import theano as thno\n",
    "import theano.tensor as T\n",
    "import arviz as az\n",
    "\n",
    "az.style.use('arviz-darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class AdditionalAttributes(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, include_additional_attr = True): # no *args or **kargs\n",
    "        self.include_additional_attr = include_additional_attr\n",
    "        self.guille_feature_names = ['H', 'dest_A', 'dest_I', 'dest_dTR', \n",
    "                                     'dest_hK', 'dest_hM', 'dest_mR', 'src_A', \n",
    "                                     'src_I', 'src_dTR', 'src_hK', 'src_hM','src_mR']\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # nothing else to do\n",
    "    def transform(self, X, y=None):\n",
    "        if self.include_additional_attr:\n",
    "            return X # might need to check if this returns pandas or a numpy, i need a numpy\n",
    "        else:\n",
    "            return X[self.guille_feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "\n",
    "def save_models(saveas, rnd_estimator, lr_estimator):\n",
    "    save_to = '../models/'\n",
    "    saveas = os.path.join(save_to, saveas)\n",
    "    if os.path.exists(saveas):\n",
    "        raise FileExistsError(f'The path \"{os.path.abspath(saveas)}\" already exists, ' \n",
    "                              'please choose a new name.')\n",
    "    else:\n",
    "        rfc_dir = os.path.join(saveas, 'rfc')\n",
    "        bayes_dir = os.path.join(saveas, 'bayes/')\n",
    "        \n",
    "        os.makedirs(rfc_dir)\n",
    "        os.mkdir(bayes_dir)\n",
    "    \n",
    "    # save random forest estimator\n",
    "    dump(rnd_estimator, os.path.join(rfc_dir, 'model.rnd'))\n",
    "    \n",
    "    # save bayesian logistic regression model\n",
    "    lr_estimator.save(bayes_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Project Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include_additional_attr = False\n",
    "dataset_filepath = \"../../big-network-attr.csv\"\n",
    "dataset_key = 'nZqfQwwiTxtRmiJ'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = pd.read_csv(dataset_filepath)\n",
    "dataset = pd.read_hdf(dataset_filepath, key=dataset_key)\n",
    "\n",
    "# Remove user_ids from dataframe\n",
    "dataset = dataset.drop(['src_user_id', 'dest_user_id'], axis=1)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.stripplot(x=\"y\", y=\"H\", data=dataset, jitter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop(\"y\", axis=1) # drop labels for training set\n",
    "y = dataset[\"y\"].copy()\n",
    "\n",
    "feature_names = X.columns.values\n",
    "\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('attribs_adder', AdditionalAttributes(include_additional_attr = include_additional_attr)),\n",
    "    ('imputer', SimpleImputer(strategy=\"mean\")),\n",
    "])\n",
    "\n",
    "# ('std_scaler', StandardScaler()),\n",
    "\n",
    "X = pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample using SMOTE balance\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_resampled, y_resampled = SMOTE(random_state=42).fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column values based on whether additional attributes is true or false\n",
    "# include_additional_attr = pipeline.named_steps['attribs_adder'].include_additional_attr\n",
    "guille_feature_names = pipeline.named_steps['attribs_adder'].guille_feature_names\n",
    "\n",
    "if not include_additional_attr:\n",
    "    feature_names = guille_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled = pd.DataFrame(X_resampled, columns=feature_names)\n",
    "y_resampled = pd.Series(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('x_train shape: ', X_train.shape)\n",
    "print ('y_train shape: ', y_train.shape)\n",
    "print ('x_test shape: ', X_test.shape)\n",
    "print ('y_test shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#g = seaborn.pairplot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "corr = X_train.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3,\n",
    "            linewidths=.5, cbar_kws={\"shrink\": .5}, ax=ax)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get most important features using Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rfc = RandomForestClassifier(random_state=42)\n",
    "\n",
    "params = {\n",
    "    'max_features': [.4,'auto', 4], \n",
    "    'n_estimators': [15, 100, 200], \n",
    "    'min_samples_leaf': [.1, 1],\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(rfc, params, n_jobs=-1).fit(X_train, y_train)\n",
    "\n",
    "clf = cv.best_estimator_\n",
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Conduct cross-validation\n",
    "acc_cv_results = cross_val_score(clf,\n",
    "                             X_train, # Feature matrix\n",
    "                             y_train, # Target vector\n",
    "                             cv=10, # Cross-validation technique\n",
    "                             scoring=\"accuracy\",\n",
    "                             n_jobs=-1) # Use all CPU scores\n",
    "\n",
    "f1_cv_results = cross_val_score(clf,\n",
    "                             X_train, # Feature matrix\n",
    "                             y_train, # Target vector\n",
    "                             cv=10, # Cross-validation technique\n",
    "                             scoring=\"f1\",\n",
    "                             n_jobs=-1) # Use all CPU scores\n",
    "\n",
    "print(f'accuracy: {acc_cv_results.mean()}\\nf1_score: {f1_cv_results.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.classifier import ConfusionMatrix\n",
    "#mapping = {1:'negative', 0:'positive'}\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "cm_viz = ConfusionMatrix(clf, classes=classes, fontsize=15)\n",
    "cm_viz.fit(X_train, y_train)\n",
    "cm_viz.score(X_test, y_test)\n",
    "cm_viz.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.classifier import ClassificationReport\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "viz = ClassificationReport(clf, classes=classes, fontsize=15)\n",
    "viz.fit(X_train, y_train)\n",
    "viz.score(X_test, y_test)\n",
    "viz.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = clf.feature_importances_\n",
    "\n",
    "feat_importances = pd.Series(importances, index=feature_names)\n",
    "n_features = feat_importances.nlargest(15)\n",
    "n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = n_features.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Bayesian Logistics Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_resampled[features]\n",
    "y = y_resampled.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('x_train shape: ', X_train.shape)\n",
    "print ('y_train shape: ', y_train.shape)\n",
    "print ('x_test shape: ', X_test.shape)\n",
    "print ('y_test shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#g = seaborn.pairplot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "corr = X_train.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3,\n",
    "            linewidths=.5, cbar_kws={\"shrink\": .5}, ax=ax)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymc3_models.models.LogisticRegression import LogisticRegression\n",
    "\n",
    "LR = LogisticRegression()\n",
    "LR.fit(X_train, y_train, inference_type='nuts', inference_args={'draws': 2000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "az.plot_trace(LR.trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = LR.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score = LR.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax= plt.subplot()\n",
    "sns.heatmap(cm, annot=True, ax = ax); #annot=True to annotate cells\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['0', '1']); ax.yaxis.set_ticklabels(['1', '0']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y_test, y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(y_test, y_score)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc_score(y_test, y_score))\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_models(saveas='big-network-full-attr', rnd_estimator=clf, lr_estimator=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
